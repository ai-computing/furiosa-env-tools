#!/usr/bin/env python3
"""
Llama-3.1-8B-Instruct ì›ë³¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (Hugging Face)
"""
import os
import shutil
from huggingface_hub import snapshot_download
from pathlib import Path

# ëª¨ë¸ ID (ì›ë³¸ Meta Llama ëª¨ë¸)
MODEL_ID = "meta-llama/Llama-3.1-8B-Instruct"

# ì €ì¥ ë””ë ‰í† ë¦¬
SAVE_DIR = Path("./models/Llama-3.1-8B-Instruct-original")
BACKUP_DIR = Path("./models/Llama-3.1-8B-Instruct-compiled-backup")

# ê¸°ì¡´ ì»´íŒŒì¼ëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë°±ì—…
OLD_DIR = Path("./models/Llama-3.1-8B-Instruct")
if OLD_DIR.exists() and (OLD_DIR / "artifact.json").exists():
    print(f"ğŸ”„ Backing up compiled model to {BACKUP_DIR}...")
    if BACKUP_DIR.exists():
        shutil.rmtree(BACKUP_DIR)
    shutil.move(str(OLD_DIR), str(BACKUP_DIR))
    print(f"âœ… Backup completed!")

SAVE_DIR.mkdir(parents=True, exist_ok=True)

print(f"ğŸ“¥ Downloading original Hugging Face model: {MODEL_ID}...")
print(f"ğŸ“‚ Save directory: {SAVE_DIR.absolute()}")
print(f"âš ï¸  This is the ORIGINAL model, not the pre-compiled FuriosaAI artifact")
print(f"âš ï¸  You will need to compile this model before inference\n")

try:
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    model_path = snapshot_download(
        repo_id=MODEL_ID,
        local_dir=str(SAVE_DIR),
        local_dir_use_symlinks=False,
        resume_download=True,
    )

    print(f"âœ… Model downloaded successfully!")
    print(f"ğŸ“ Model path: {model_path}")

    # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ì¶œë ¥
    print("\nğŸ“‹ Downloaded files:")
    for file in sorted(SAVE_DIR.rglob("*")):
        if file.is_file():
            size_mb = file.stat().st_size / (1024 * 1024)
            print(f"  - {file.relative_to(SAVE_DIR)}: {size_mb:.2f} MB")

except Exception as e:
    print(f"âŒ Error downloading model: {e}")
    raise
